---
title: "HW6 Telemarketing"
author: "Jack Yu, Ken Bai"
date: "3/22/2020"
output:
  html_document:
    toc: true
    theme: readable
    highlight: tango
    code_folding: show
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

## Downloading and Prepping the Data

```{r}
#Downloading and Prepping the Data
tele <- read.csv("tele.csv", stringsAsFactors = TRUE)
summary(tele)

#We are deleting the "duration" variable because it is an after the fact measurement. We only should be using variables that we know before the call
tele$duration <- NULL

# Deleting the column X
tele$X <- NULL

# Changing pdays to a dummy and deleting pdays
tele$pdaysdummy <- ifelse(tele$pdays == 999, 0, 1)
tele$pdays <- NULL

str(tele)
```

## Getting Data Ready for Analysis

```{r, cache = TRUE}
# Using model.matrix to convert all the factors to dummy variables
# We are converting all of the factors into dummy variables as the input into knn has to be numeric

telemm <- as.data.frame(model.matrix(~.-1,tele))
str(telemm)

# Randomize the rows in the data (shuffling the rows)
set.seed(12345)
tele_random <- telemm[sample(nrow(telemm)),]

#Normalize the data
normalize <- function(x) {
  return ((x - min(x)) / (max(x) - min(x)))
}

# we are going to normalize everything 
tele_norm <- as.data.frame(lapply(tele_random, normalize))

str(telemm)
```


## Getting Train and Test Samples for KNN

```{r}
# Selects 10000 random rows for test data
set.seed(12345)
test_set <- sample(1:nrow(tele_norm), 10000) 
# Depending on R-version and computer, different rows may be selected. 
# If that happens, results are different. 

# Create a train set and test set
#First the predictors - all columns except the yyes column
tele_train <- tele_norm[-test_set, -match("yyes",names(tele_norm))]
tele_test <- tele_norm[test_set, -match("yyes",names(tele_norm))]

#Now the response (aka Labels) - only the yyes column
tele_train_labels <- tele_norm[-test_set, "yyes"]
tele_test_labels <- tele_norm[test_set, "yyes"]
```

> Now you are ready to build your ANN model. Feel free to modify the data load, cleaning and preparation code above as per your preference.

## ANN model

```{r}
library(neuralnet)
ANN_train <- tele_norm[-test_set,]
ANN_test <- tele_norm[test_set,]
ANN_model <- neuralnet(formula = yyes ~ ., data = ANN_train)
plot(ANN_model)
```

## Evaluate ANN Model

```{r}
library(gmodels)
library(class)
library(caret)
ANN_pred_1 <- predict(ANN_model, tele_test)
threshold <- 0.5
predicted_yyes_1 <- ifelse(ANN_pred_1 < threshold, 0, 1)
CrossTable(x = ANN_test$yyes, y = predicted_yyes_1, prop.chisq=FALSE)
confusionMatrix(as.factor(predicted_yyes_1), as.factor(ANN_test$yyes), positive = "1")


# a more complex neural network topology with 5 hidden neurons
ANN_model2 <- neuralnet(yyes ~ ., data = ANN_train, hidden = 5)

# plot the network
plot(ANN_model2)

# evaluate the results as we did before
model_results2 <- compute(ANN_model2, ANN_test)
predicted_yyes_2 <- model_results2$net.result
cor(predicted_yyes_2, ANN_test$yyes)
```

#Perform KNN model
```{r}
library(class)
library(caret)

#Run KNN on train data, create predictions for test data
#Starting K value close to sqrt(nrow(wbcd_train))
tele_test_pred <- knn(train = tele_train, test = tele_test,
                      cl = tele_train_labels, k=sqrt(nrow(tele_train)))

#Evaluate model results
library(gmodels)
CrossTable(x = tele_test_labels, y = tele_test_pred, 
           prop.chisq=FALSE)

confusionMatrix(as.factor(tele_test_pred), as.factor(tele_test_labels), positive = "1")
```

